{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from scipy.stats import zscore\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw training data that was created in Stage 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('../amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure helpful score\n",
    "After the first submission, I changed the helpful score to be more lenient and slightly higher (more strict) when considering the helful denominator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon['helpful'] = (amazon['helpScore']>=.67) & (amazon['HelpfulnessDenominator']>4)\n",
    "# print(amazon['helpful'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NaN\n",
    "I also removed helpScores that were NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190908, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = amazon[np.isfinite(amazon['helpScore'])]\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# V = set(amazon['Text'])\n",
    "# amazon[long_words] = [w for w in set(amazon['Text']) if len(w) > 13]\n",
    "# sorted(set(amazon['Text']))\n",
    "# amazon['v'] = amazon[word_count]\n",
    "# print(amazon['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This view provides the first five lines of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      233579        314180  314181  B002EDIJX6  A29J8R14DE7J5D   \n",
      "1      328779        277777  277778  B002OMV09W   A20FWCIY7HIAQ   \n",
      "2       42396        161359  161360  B008O3G2K2  A1QBOC76MIOJYP   \n",
      "4      378479        287581  287582  B000IEHR6S  A2G31BUNV2GD70   \n",
      "5      218113         87153   87154  B000FGCA16  A169QQNCP4W4P2   \n",
      "\n",
      "         ProfileName  HelpfulnessNumerator  HelpfulnessDenominator  Score  \\\n",
      "0  R. Hill \"msrhook\"                     2                       2      5   \n",
      "1  Ryan L. Wilkinson                     1                       1      5   \n",
      "2          MyPenName                     1                       2      2   \n",
      "4            oldsoup                     4                       4      2   \n",
      "5       Douglas Hoag                     2                       2      5   \n",
      "\n",
      "         Time                                 Summary  \\\n",
      "0  1320105600                         cookie memories   \n",
      "1  1312329600      3 cans purchased, 4 plants yielded   \n",
      "2  1328400000                      Somewhat undecided   \n",
      "4  1188345600                 Too much sugar is added   \n",
      "5  1308441600  Very Special Rice Noodles from La Choy   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  This is a cookie as a child I have visit the f...        1.0    False  \n",
      "1  These were given as a gift and so far they hav...        1.0    False  \n",
      "2  This product is a bit odd, to say the least. I...        0.5    False  \n",
      "4  Too much sugar is added to the dried mango. It...        1.0    False  \n",
      "5  We have been cooking Asian cuisine for many ye...        1.0    False  \n",
      "0.157300898862\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction on natural language data - this step creates a large matrix.  It was the code that was used for a previous in-class assignment.\n",
    "Using NLTK and k-means clustering, I tried to see if there was a way to cluster the two groups and distinguish the differences in common words between helpful and not helpful scores.  It was not very useful, and the process of tokenizing and clustering took a long time.  I can see why hashing is so useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A hashing method is used to create matrix that is smaller in size and easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hubideal/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/hubideal/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190908, 131072)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True, ngram_range=(1,3))\n",
    "X_hv = hv.fit_transform(amazon.Text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code creates a pickle file so we can treat the training and test set the same way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv, 'hv.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This step is optional:  Transformation on the word counts can sometimes improves performance.  \n",
    "##### notes:  Should I keep or not.  Term frequency.  IDF Inverse document frequency.  is the total number of documents divided by the number of documents that contain the term (log of this). idf is weighting.  reduces the weight of less influential words.  Like \"and\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Note:  This is where I can add and remove features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amazon['reviewLen'] = zscore(amazon['Text'].str.len())\n",
    "# amazon['summaryLen'] = amazon['Summary'].str.len()\n",
    "# amazon['userIdLen'] = zscore(amazon['UserId'].str.len())\n",
    "# amazon['idLen'] = zscore(amazon['Id'])\n",
    "# amazon['profileLen'] = amazon['ProfileName'].str.len()\n",
    "# amazon['zScore'] = zscore(amazon['Score'])\n",
    "\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "amazon['summaryLen'] = amazon['Summary'].str.len()\n",
    "amazon['wordCount'] = amazon['Text'].str.split().apply(len)\n",
    "\n",
    "amazon['wordArray'] = amazon['Text'].str.split()\n",
    "amazon['wordArrayLen'] = amazon['wordArray'].str.len()\n",
    "amazon['userIdLen'] = amazon['UserId'].str.len()\n",
    "amazon['idLen'] = amazon['Id']\n",
    "amazon['profileLen'] = amazon['ProfileName'].str.len()\n",
    "amazon['zScore'] = amazon['Score']\n",
    "amazon['avgWord'] = amazon['reviewLen']/amazon['wordCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "amazon['summaryLen'].fillna(0, inplace=True)\n",
    "print(np.any(np.isnan(amazon['summaryLen'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "amazon['profileLen'].fillna(0, inplace=True)\n",
    "print(np.any(np.isnan(amazon['profileLen'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize as WordTokenizer\n",
    "\n",
    "# def custom_tokenize(text):\n",
    "#     if not text:\n",
    "#         print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "#         text = ''\n",
    "#     return WordTokenizer(text)\n",
    "# amazon['tokenize'] = amazon['Text'].apply(custom_tokenize)\n",
    "\n",
    "#amazon['cols'] = df.blocks['object'].amazon['wordArray']\n",
    "# def word_tokenizer(amazon, wordArray):\n",
    "#     token=[]\n",
    "#     for item in amazon['wordArray']:\n",
    "#          token.append(WordTokenizer(item))\n",
    "\n",
    "#     return token\n",
    "\n",
    "# token = word_tokenizer(amazon, 'wordArray')\n",
    "# df. insert(index, 'token_column', token)\n",
    "\n",
    "# print(nltk.FreqDist(amazon[\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amazon['summaryLen'] = zscore(amazon['summaryLen'])\n",
    "# amazon['profileLen'] = zscore(amazon['profileLen'])\n",
    "\n",
    "\n",
    "\n",
    "def word_counter(text):\n",
    "    counter=0\n",
    "    for word in text:\n",
    "        if word == \"is\" or word == 'are' or word == \"was\" or word == \"were\" or word == \"can\" or word == \"could\" or word == \"will\" or word == \"would\" or word == \"become\" or word == \"have\" or word == \"has\" or word == \"had\":\n",
    "            counter=counter+1\n",
    "    return counter\n",
    "\n",
    "amazon['wordCount'] = amazon['wordArray'].apply(word_counter)\n",
    "amazon['passivePer'] = amazon['wordCount'] / amazon['wordArrayLen']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def word_counter(text):\n",
    "#     counter=0\n",
    "#     for word in text:\n",
    "#         if word == \"excellent\" or word == 'yum' or word == \"good\" or word == \"dog\" or word == \"dogs\" or word == \"!\" or word == \"fantastic\" or word == \"helpful\" or word == \"product\" or word == \"bought\" or word == \"recommend\":\n",
    "#             counter=counter+1\n",
    "#     return counter\n",
    "\n",
    "# amazon['wordCount2'] = amazon['wordArray'].apply(word_counter)\n",
    "# amazon['goodWords'] = amazon['wordCount2'] / amazon['wordArrayLen']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_capitalize(text):\n",
    "    counter=0\n",
    "    for word in text:\n",
    "        #if word == 'tea' or word == 'get' or word == 'years' or word == 'oil' or word == 'cat' or word == 'quality' or word == 'milk' or word == 'less' or word == 'brand' or word == 'give' or word == 'lot' or word == 'stuff' or word == 'ingredients' or word == 'back':\n",
    "        if  word == 'love' or word == 'taste' or word =='liked' or word ==\"n't\" or word =='great' or word =='good' or word =='flavors' or word =='product' or word =='very' or word =='using' or word =='just' or word =='trying' or word =='buy' or word =='food' or word =='make' or word =='order' or word =='price' or word =='eating' or word =='time' or word =='best' or word =='really' or word =='only' or word =='amazon' or word =='little' or word =='stores' or word ==\"'ve\" or word =='better' or word =='because' or word =='did' or word =='does' or word ==\"'m\" or word =='any' or word =='br' or word =='br' or word =='verified' or word =='purchased': \n",
    "        #word == 'I' or word == 'you' or word == 'my' or word == 'like' or word == 'good' or word == 'one' or word == 'food' or word == 'all' or word == 'more' or word == 'very' or word == 'product' or word == 'taste' or word == 'out' or word == 'me' or word == 'flavor' or word == 'tea' or word == 'great' or word == 'coffee' or word == 'get' or word == 'up' or word == 'use' or word == 'only' or word == 'no' or word == 'much' or word == 'we' or word == 'little' or word == 'time' or word == 'love' or word == 'My' or word == 'too' or word == 'make' or word == 'tried' or word == 'Amazon' or word == 'find' or word == 'best' or word == 'better' or word == 'water' or word == 'price' or word == 'eat' or word == 'used' or word == 'dog' or word == 'buy' or word == 'now' or word == 'first' or word == 'try' or word == 'found' or word == 'We' or word == 'sugar' or word == 'cup' or word == 'then' or word == 'made' or word == 'over' or word == '2' or word == 'our' or word == 'day' or word == 'years' or word == 'oil' or word == 'chocolate' or word == 'cat' or word == 'know' or word == 'box' or word == 'bought' or word == 'think' or word == 'store' or word == 'go' or word == 'quality' or word == 'want' or word == 'recommend' or word == 'milk' or word == 'less' or word == 'mix' or word == 'never' or word == 'brand' or word == 'without' or word == 'every' or word == 'You' or word == 'sweet' or word == 'give' or word == 'lot' or word == 'again' or word == 'drink' or word == 'stuff' or word == 'order' or word == 'ingredients' or word == 'back' or word == 'got' or word == 'tastes' or word == '1' or word == 'makes' or word == 'say':\n",
    "            counter=counter+1\n",
    "                \n",
    "    return counter\n",
    "\n",
    "amazon['wordCapitalize'] = amazon['wordArray'].apply(word_capitalize)\n",
    "amazon['capitalism'] = amazon['wordCapitalize'] / amazon['wordArrayLen']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amazon['avgWord'] = zscore(amazon['avgWord'])\n",
    "# amazon[\"Score\"] = zscore(amazon[\"Score\"])\n",
    "# amazon[\"passivePer\"] = zscore(amazon[\"passivePer\"])\n",
    "# amazon['capitalism'] = zscore(amazon['capitalism'])\n",
    "# amazon[\"mystery\"] = zscore(amazon['Unnamed: 0'])\n",
    "# amazon[\"Time\"] = zscore(amazon['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Score   avgWord  passivePer  capitalism\n",
      "0       5  4.906250    0.046875    0.062500\n",
      "1       5  5.130000    0.040000    0.010000\n",
      "2       2  5.142450    0.045584    0.048433\n",
      "4       2  5.622951    0.114754    0.000000\n",
      "5       5  5.547368    0.084211    0.021053\n",
      "10      5  5.238095    0.047619    0.023810\n",
      "12      4  4.666667    0.117647    0.058824\n",
      "16      5  5.409091    0.075758    0.045455\n",
      "17      5  5.178571    0.053571    0.053571\n",
      "18      1  4.765957    0.063830    0.085106\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "# amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "# amazon['profileLen'] = (amazon['ProfileName'].str.len())/1\n",
    "\n",
    "#\"zScore\", 'avgWord', 'userIdLen', 'wordCount', \"Score\", 'Unnamed: 0' , 'wordCount','goodWords', 'capitalism', 'passivePer'\n",
    "X_quant_features = amazon[[ 'Score', 'avgWord', 'passivePer', 'capitalism']]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:  This creates a CSR Matrix.  Horizontal stack so we can concatenate horizontally.  spare matrix.  and combine them hstack from the bag of words and horizontally conatenate that.  Add to two columns.  using the sparse data structure.  Single sparse matrix.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190908, 131076)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:  Nomralize everything on the same scale.  Use the standard scaler which takes an input matrix.  the two new columns that are added are the same as the count of the words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190908, 131076)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit models - I will focus on the Linear model for the first assignment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note;  In my original iteration, I just focused on using the defaults.  fit the support vector machine with the x and y variables.  Take a snap shot of that fit for the test v.  92% accuracy.  Lots of false positive and false negatives.  SVM - look at graph.  We are really only fitting on proximity.  closest points to the point of delineation (line).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hubideal/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 30030, 'Neg': 160878, 'TP': 28692, 'TN': 158555, 'FP': 2323, 'FN': 1338, 'Accuracy': 0.98082322375175479, 'Precision': 0.92510075769788813, 'Recall': 0.95544455544455542, 'desc': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier(alpha= .0001)\n",
    "svm.fit(X, y)\n",
    "joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "svm_performance.compute_measures()\n",
    "print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # MODEL: SVM, linear\n",
    "# from sklearn import linear_model\n",
    "# svm = linear_model.SGDClassifier(alpha=.000001)\n",
    "# svm.fit(X, y)\n",
    "# joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "# svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "# svm_performance.compute_measures()\n",
    "# print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on log regression:  Introduce new models.  this one is logistic regression.  The other are Naive Bayes and ridge regression.  These are all variatons of the linear model.  Linear regression is difficult to fit sometimes - crude.  How can we get better results from it.  Outcome the logistic regression is bianary.  Assumed to be bianary.  Log of the outcome.  Actually its the log of the probability of the outcome.  We think of it as what is the probility of one given everything else.  the likihood of the outcome being one or true and transform it into a distribution.  All of these transfomrations happen on the x side.  We can play around with the defaults.  alpha scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 30030, 'Neg': 160878, 'TP': 29784, 'TN': 160675, 'FP': 203, 'FN': 246, 'Accuracy': 0.99764808179856268, 'Precision': 0.99323039983993067, 'Recall': 0.9918081918081918, 'desc': 'lgs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "lgs = linear_model.SGDClassifier(loss='log', max_iter=10, alpha=.01)\n",
    "lgs.fit(X, y)\n",
    "joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "    \n",
    "lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "lgs_performance.compute_measures()\n",
    "\n",
    "print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # MODEL: logistic regression\n",
    "# from sklearn import linear_model\n",
    "# lgs = linear_model.SGDClassifier(loss='log', alpha=.000001)\n",
    "# lgs.fit(X, y)\n",
    "# joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "# lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "# lgs_performance.compute_measures()\n",
    "# print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on Naive Bayes.  P(Y|X) = P(X|Y)P(Y)/P(x)  Y is informed by taking a look at x.  We start witht he probability of x given the probility of y.  multiplyed the probility of y divided by the probility x.   adding naive becasue its impossible to assume all of are xs are independent of each other.  We aregoing to pretend that the xs are independent.  Breaking assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on Ridge Regression:  Since we are trying to find things that are good.  FP is high for the ridge regression - which is good.  it is the closest to the linear model.  The only difference is that you are using a regulaization for the coefficients.  This is a term down weights every coefficient.  Therefore, it makes it harder for any individual to be really strong predictor of the outcome.  As alpha become smaller the weight can become bigger.  Ridge is weighting down the weights.  Beyond ridge there are implementions of ridge that allow you specific different alphas, etc.  There is a implementation of Naive Bayes that is a ridge naive bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 30030, 'Neg': 160878, 'TP': 23334, 'TN': 142448, 'FP': 18430, 'FN': 6696, 'Accuracy': 0.86838686697257317, 'Precision': 0.5587108514510104, 'Recall': 0.77702297702297707, 'desc': 'nbs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbs = MultinomialNB(alpha=.1)\n",
    "nbs.fit(X, y)\n",
    "joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "    \n",
    "nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "nbs_performance.compute_measures()\n",
    "\n",
    "print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 30030, 'Neg': 160878, 'TP': 13529, 'TN': 141656, 'FP': 19222, 'FN': 16501, 'Accuracy': 0.81287845454354979, 'Precision': 0.41308662330921192, 'Recall': 0.45051615051615052, 'desc': 'rdg'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Ridge Regression Classifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "#alphaTerm=[.000001, .00001, .0001, .0001, .001, .01, .1, 1, 2, 3, 5, 9, 10, 50, 100, 200, 300, 1000, 10000]\n",
    "#for i in range(len(alphaTerm)):\n",
    "rdg = linear_model.RidgeClassifier(alpha=9050, normalize=True, fit_intercept=True, max_iter=100)\n",
    "rdg.fit(X, y)\n",
    "joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "    \n",
    "rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "rdg_performance.compute_measures()\n",
    "print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll talk about this one next week.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron', eta0=6, max_iter=20, alpha=.1)\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "# prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "# prc_performance.compute_measures()\n",
    "# print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# alphaTerm=[.00001, .0001, .001, .01, .1, 1, 2, 10, 20, 40, 50, 60, 70]\n",
    "# for i in range(len(alphaTerm)):\n",
    "#     prc = linear_model.SGDClassifier(loss='perceptron', eta0=12, max_iter=20, alpha = alphaTerm[i]) #, alpha=2\n",
    "#     prc.fit(X, y)\n",
    "#     joblib.dump(prc, 'prc.pkl') # pickle\n",
    "#     prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "#     prc_performance.compute_measures()\n",
    "#     print(alphaTerm[i])\n",
    "#     print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 30030, 'Neg': 160878, 'TP': 29729, 'TN': 160634, 'FP': 244, 'FN': 301, 'Accuracy': 0.99714522178221976, 'Precision': 0.99185934007273213, 'Recall': 0.98997668997668997, 'desc': 'prc'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron', eta0=4, max_iter=42, alpha=10)\n",
    "prc.fit(X, y)\n",
    "joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron', eta0=6, max_iter=20, alpha=.1)\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "# prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "# prc_performance.compute_measures()\n",
    "# print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns0xOFGZmlsmJwszMMjlRmJlZpv8Pnw4EMPRAjTMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a85afb0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
