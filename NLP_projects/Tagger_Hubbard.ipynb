{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging with Hidden Markov Models \n",
    "---\n",
    "### Introduction\n",
    "\n",
    "Part of speech tagging is the process of determining the syntactic category of a word from the words in its surrounding context. It is often used to help disambiguate natural language phrases because it can be done quickly with high accuracy. Tagging can be used for many NLP tasks like determining correct pronunciation during speech synthesis (for example, _dis_-count as a noun vs dis-_count_ as a verb), for information retrieval, and for word sense disambiguation.\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read and preprocess the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "There are 45872 sentences in the training set.\n",
      "There are 11468 sentences in the testing set.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-38532\n",
      "words:\n",
      "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
      "tags:\n",
      "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-38532'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 928458 samples of 50536 unique words in the training set.\n",
      "There are 232734 samples of 25112 unique words in the testing set.\n",
      "There are 5521 words in the test set that are missing in the training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the training set.\"\n",
    "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the testing set.\"\n",
    "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
    "\n",
    "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
    "       \"The number of training + test samples should sum to the total number of samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing words with Dataset.X and tags with Dataset.Y \n",
    "for i in range(2):    \n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(\"\\t\", pair)\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build a Most Frequent Class tagger\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "    \n",
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \n",
    "    \"\"\"Here I am returning a dictionary keyed to each unique value in the first \n",
    "    sequence list that counts the number of occurrences of the corresponding \n",
    "    value from the second sequences list.\n",
    "    \n",
    "    For example, it does not matter if seq a is words or tags.  The first seq\n",
    "    is the unique value, and the second sequ is how many times the unique value\n",
    "    appears as a seq B value.  It could be [NOUN]:[time]==?\"\"\"\n",
    "\n",
    "    dic = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for seqA, seqB in zip(sequences_A, sequences_B):\n",
    "        dic[seqA][seqB] += 1\n",
    "\n",
    "    return dic\n",
    "    \n",
    "\n",
    "emission_counts = pair_counts([item for sub_list in data.training_set.Y for item in sub_list], [item for sub_list in data.training_set.X for item in sub_list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent Class Tagger\n",
    "I will use the pair_counts() function again and the training dataset.  I want to find the most frequent class label for each word in the training data, and populate the mfc_table below. \n",
    "The table:  [Word]:[max(Tag)]\n",
    "\n",
    "The MFCTagger class is provided to mock the interface of Pomegranite HMM models so that they can be used interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I am creating a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
    "from collections import namedtuple\n",
    "import operator\n",
    "\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class MFCTagger:\n",
    "\n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "\n",
    "word_counts = pair_counts([item for sub_list in data.training_set.X for item in sub_list],[item for sub_list in data.training_set.Y for item in sub_list])\n",
    "\n",
    "def to_table(word_dict):\n",
    "    m = defaultdict(lambda: \"MISSING\")\n",
    "    l = {}\n",
    "    for k, word in enumerate(word_dict):\n",
    "        subDict = word_dict[word]\n",
    "        for i in subDict:\n",
    "            int(subDict[i])\n",
    "        wordMax = max(subDict, key=word_dict[word].get)\n",
    "        valueMax = max(subDict.values())\n",
    "\n",
    "        m[word] = wordMax\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "mfc_table = to_table(word_counts) \n",
    "\n",
    "mfc_model = MFCTagger(mfc_table) # Create a Most Frequent Class tagger instance\n",
    "\n",
    "assert len(emission_counts) == 12, \\\n",
    "        \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
    "        \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following below are helper functions.  They interface with the Pomegranate network models & the mocked MFCTagger to take advantage of the missing value functionality in Pomegranate through a simple sequence decoding function. Run these functions, then run the next cell to see some of the predictions made by the MFC tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "\n",
    "\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with MFC Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the following functions to evaluate the accuracy of the MFC tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "    \n",
    "        \n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "           \n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "     \n",
    "    return correct / total_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy of the MFC tagger\n",
    "Run the next cell to evaluate the accuracy of the tagger on the training and test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.72%\n",
      "testing accuracy mfc_model: 93.01%\n"
     ]
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Counts\n",
    "count the occurances of each of the 12 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 220632, 'VERB': 146161, '.': 117757, 'ADP': 115808, 'DET': 109671, 'ADJ': 66754, 'ADV': 44877, 'PRON': 39383, 'CONJ': 30537, 'PRT': 23906, 'NUM': 11878, 'X': 1094})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def unigram_counts(sequences):\n",
    "\n",
    "    dic = Counter()\n",
    "    s = [item for sub_list in sequences for item in sub_list]\n",
    "    for t in s:\n",
    "        dic[t] += 1    \n",
    "    return dic\n",
    "    raise NotImplementedError\n",
    "\n",
    "tag_unigrams = unigram_counts(data.training_set.Y)\n",
    "print(tag_unigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function below to estimate the co-occurrence frequency of each pair of symbols in each of the input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bigram_counts(sequences):\n",
    "\n",
    "    \n",
    "    dic = Counter(sequences)\n",
    "    return dic\n",
    "    \n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]  #got help from:  https://towardsdatascience.com/part-of-speech-tagging-with-hidden-markov-chain-models-e9fccc835c0e\n",
    "biTags = [(tags[i],tags[i+1]) for i in range(0,len(tags)-1)]  #got help from: https://towardsdatascience.com/part-of-speech-tagging-with-hidden-markov-chain-models-e9fccc835c0e\n",
    "tag_bigrams = bigram_counts(biTags)\n",
    "print(len(tag_bigrams))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Starting Counts\n",
    "Count the number of times a sentence starts with one of the 12 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def starting_counts(sequences):\n",
    "\n",
    "    tagList = ['CONJ', 'NOUN', 'NUM', '.','PRON', 'VERB', 'DET', 'ADP', 'ADJ', 'PRT', 'ADV', 'X']\n",
    "    ee = {}\n",
    "\n",
    "    for numa, a in enumerate(tagList):\n",
    "        if a not in ee:\n",
    "            cnt3 = 0\n",
    "            for j in sequences:\n",
    "                if a == j[0]:\n",
    "                    cnt3+=1\n",
    "                ee[a] = cnt3\n",
    "    print(len(ee))\n",
    "    return ee\n",
    "    \n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: Calculate the count of each tag starting a sequence\n",
    "tag_starts = starting_counts(data.training_set.Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def ending_counts(sequences):\n",
    "\n",
    "    tagList = ['CONJ', 'NOUN', 'NUM', '.','PRON', 'VERB', 'DET', 'ADP', 'ADJ', 'PRT', 'ADV', 'X']\n",
    "    ff = {}\n",
    "\n",
    "    for numa, a in enumerate(tagList):\n",
    "        if a not in ff:\n",
    "            cnt4 = 0\n",
    "            for j in sequences:\n",
    "                k=len(j)\n",
    "                if a == j[k-1]:\n",
    "                    cnt4+=1\n",
    "                ff[a] = cnt4\n",
    "    print(len(ff))\n",
    "    return ff\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "tag_ends = ending_counts(data.training_set.Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic HMM Tagger\n",
    "Here I am using the tag unigrams and bigrams calculated above to construct a hidden Markov tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{\n",
      "    \"class\" : \"State\",\n",
      "    \"distribution\" : {\n",
      "        \"class\" : \"Distribution\",\n",
      "        \"name\" : \"DiscreteDistribution\",\n",
      "        \"parameters\" : [\n",
      "            {\n",
      "                \"the\" : 0.45767375327509324,\n",
      "                \"some\" : 0.010129981973302973,\n",
      "                \"whose\" : 0.0018245644764594692,\n",
      "                \"an\" : 0.025755552149701866,\n",
      "                \"those\" : 0.0057072376823652194,\n",
      "                \"which\" : 0.025828534728760243,\n",
      "                \"My\" : 0.001123931717499033,\n",
      "                \"a\" : 0.15962749691648603,\n",
      "                \"his\" : 0.04691320181872587,\n",
      "                \"any\" : 0.009400156182719185,\n",
      "                \"this\" : 0.02893759259664718,\n",
      "                \"whatever\" : 0.0006276501799020573,\n",
      "                \"each\" : 0.005539377750530948,\n",
      "                \"its\" : 0.01299089907239142,\n",
      "                \"that\" : 0.014457848911464833,\n",
      "                \"every\" : 0.0031674439311336383,\n",
      "                \"This\" : 0.008604646070982856,\n",
      "                \"our\" : 0.008334610528466855,\n",
      "                \"no\" : 0.01150935271750633,\n",
      "                \"my\" : 0.008465979170771937,\n",
      "                \"The\" : 0.052970755880571305,\n",
      "                \"these\" : 0.008962260708368912,\n",
      "                \"both\" : 0.004692779833453755,\n",
      "                \"your\" : 0.006334887862267277,\n",
      "                \"These\" : 0.0025178989775140673,\n",
      "                \"their\" : 0.0186908384968508,\n",
      "                \"what\" : 0.010473000094877352,\n",
      "                \"What\" : 0.003379093410402937,\n",
      "                \"another\" : 0.004181901780045103,\n",
      "                \"Their\" : 0.0007809135959246528,\n",
      "                \"An\" : 0.0014377568074500618,\n",
      "                \"A\" : 0.008743312971193776,\n",
      "                \"her\" : 0.012983600814485583,\n",
      "                \"Some\" : 0.0015034411286026026,\n",
      "                \"That\" : 0.002123793050598822,\n",
      "                \"His\" : 0.0038607784321882366,\n",
      "                \"Her\" : 0.0010947386858756814,\n",
      "                \"ani\" : 1.4596515811675753e-05,\n",
      "                \"Its\" : 0.0005692641166553544,\n",
      "                \"Every\" : 0.000416000700632759,\n",
      "                \"either\" : 0.0004305972164444347,\n",
      "                \"Each\" : 0.0008611944328888694,\n",
      "                \"No\" : 0.001766178413212766,\n",
      "                \"Our\" : 0.0008028083696421664,\n",
      "                \"Which\" : 0.00015326341602259541,\n",
      "                \"Another\" : 0.0008101066275480043,\n",
      "                \"Both\" : 0.0006349484378078953,\n",
      "                \"neither\" : 0.00016056167392843328,\n",
      "                \"Your\" : 0.0004014041848210832,\n",
      "                \"another's\" : 3.649128952918938e-05,\n",
      "                \"Any\" : 0.00031382508995102867,\n",
      "                \"them\" : 7.298257905837876e-05,\n",
      "                \"Those\" : 0.0004962815375969756,\n",
      "                \"Thy\" : 3.649128952918938e-05,\n",
      "                \"Neither\" : 0.00010947386858756815,\n",
      "                \"whichever\" : 3.649128952918938e-05,\n",
      "                \"'nother\" : 7.298257905837877e-06,\n",
      "                \"Ye\" : 7.298257905837877e-06,\n",
      "                \"thy\" : 5.1087805340865136e-05,\n",
      "                \"Either\" : 2.9193031623351507e-05,\n",
      "                \"thees\" : 7.298257905837877e-06,\n",
      "                \"Whatever\" : 0.00018245644764594692,\n",
      "                \"mah\" : 1.4596515811675753e-05,\n",
      "                \"hys\" : 3.649128952918938e-05,\n",
      "                \"anye\" : 7.298257905837877e-06,\n",
      "                \"Them\" : 1.4596515811675753e-05,\n",
      "                \"Whichever\" : 7.298257905837877e-06,\n",
      "                \"ever'\" : 7.298257905837877e-06,\n",
      "                \"thease\" : 7.298257905837877e-06,\n",
      "                \"myn\" : 7.298257905837877e-06,\n",
      "                \"hir\" : 7.298257905837877e-06,\n",
      "                \"th'\" : 7.298257905837877e-06,\n",
      "                \"thet\" : 7.298257905837877e-06,\n",
      "                \"enny\" : 7.298257905837877e-06,\n",
      "                \"yore\" : 7.298257905837877e-06,\n",
      "                \"Whose\" : 7.298257905837877e-06,\n",
      "                \"one\" : 1.4596515811675753e-05,\n",
      "                \"whichever-the-hell\" : 7.298257905837877e-06,\n",
      "                \"out\" : 7.298257905837877e-06,\n",
      "                \"ether\" : 7.298257905837877e-06,\n",
      "                \"myne\" : 7.298257905837877e-06,\n",
      "                \"Y'r\" : 7.298257905837877e-06,\n",
      "                \"mine\" : 7.298257905837877e-06,\n",
      "                \"Whosever\" : 7.298257905837877e-06,\n",
      "                \"thine\" : 7.298257905837877e-06,\n",
      "                \"ther\" : 1.4596515811675753e-05,\n",
      "                \"nether\" : 7.298257905837877e-06\n",
      "            }\n",
      "        ],\n",
      "        \"frozen\" : false\n",
      "    },\n",
      "    \"name\" : \"DET\",\n",
      "    \"weight\" : 1.0\n",
      "}\n",
      "i added state\n",
      "i added starts\n",
      "i added ends\n",
      "i added bigrams\n",
      "baked\n"
     ]
    }
   ],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "\n",
    "tagList = ['CONJ', 'NOUN', 'NUM', '.','PRON', 'VERB', 'DET', 'ADP', 'ADJ', 'PRT', 'ADV', 'X']\n",
    "\n",
    "cUT = sum(tag_unigrams.values())\n",
    "cBT = sum(tag_bigrams.values())\n",
    "strT = sum(tag_starts.values())\n",
    "endT = sum(tag_ends.values())\n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.stream())]\n",
    "\n",
    "words = [word for i, (word, tag) in enumerate(data.stream())]\n",
    "\n",
    "tag_complete_dict=pair_counts(tags,words)\n",
    "\n",
    "create_state = {}\n",
    "for tag, words_dict in tag_complete_dict.items():\n",
    "    total = sum(words_dict.values())\n",
    "    discTag = {word: count/total for word, count in words_dict.items()}\n",
    "    tag_emissions = DiscreteDistribution(discTag)\n",
    "    tag_state = State(tag_emissions, name=tag)\n",
    "    create_state[tag]=tag_state\n",
    "    \n",
    "print(len(create_state))\n",
    "print(create_state['DET'])\n",
    "\n",
    "for tag in create_state:\n",
    "    basic_model.add_state(create_state[tag])\n",
    "\n",
    "print(\"i added state\")   \n",
    "\n",
    "startDictTag = {}\n",
    "for sttag in tag_starts:\n",
    "    tagVal = tag_starts[sttag]\n",
    "    propStTag = tagVal/cUT\n",
    "    startDictTag[sttag] = propStTag\n",
    "    \n",
    "for tag in create_state:\n",
    "    basic_model.add_transition(basic_model.start,create_state[tag], startDictTag[tag])\n",
    "\n",
    "print(\"i added starts\")\n",
    "\n",
    "endDictTag = {}\n",
    "for endtag in tag_ends:\n",
    "    tagVal = tag_ends[endtag]\n",
    "    propEnTag = tagVal/cUT\n",
    "    endDictTag[endtag] = propEnTag\n",
    "    \n",
    "for tag in create_state:\n",
    "    basic_model.add_transition(create_state[tag], basic_model.end, endDictTag[tag])\n",
    "\n",
    "print(\"i added ends\")\n",
    "\n",
    "for bittag1 in tagList:\n",
    "    for bittag2 in tagList:\n",
    "        callBi = (bittag1, bittag2)\n",
    "        btagValue = tag_bigrams[callBi]\n",
    "        countBiTag = tag_unigrams[bittag1]\n",
    "        propBiTag = btagValue/countBiTag\n",
    "        basic_model.add_transition(create_state[bittag1], create_state[bittag2], propBiTag)\n",
    "\n",
    "print(\"i added bigrams\")\n",
    "    \n",
    "basic_model.bake()\n",
    "print(\"baked\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.52%\n",
      "testing accuracy basic hmm model: 96.13%\n"
     ]
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Sequences with the HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
