{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis -- More MOVIE Revies\n",
    "\n",
    "_Natural Langauge Processing \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb  # import the built-in imdb dataset in Keras\n",
    "\n",
    "vocabulary_size = 5000\n",
    "\n",
    "# Loading the training and test data (note the difference in convention compared to scikit-learn)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "print(\"Loaded dataset with {} training samples, {} test samples\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Review ---\n",
      "[1, 660, 6, 22, 9, 2279, 218, 2707, 6, 78, 155, 146, 55, 1688, 8, 106, 6, 2279, 22, 48, 50, 9, 6, 213, 8, 30, 93, 5, 14, 31, 434, 47, 31, 45, 4, 400, 2, 65, 7, 6, 1619, 132, 5, 27, 223, 17, 36, 585, 111, 153, 7, 199, 2, 5, 958, 21, 13, 215, 3081, 25, 15, 14, 238, 43, 30, 44, 4, 91, 2279, 22, 8, 216, 46, 7, 363, 11, 4, 3814, 88, 2, 113, 11, 2714, 16, 1211, 8, 135, 4, 222, 30, 2848, 8, 106, 3309, 44, 2, 341, 5, 3497, 10, 10, 44, 4, 64, 1566, 85, 74, 4, 2, 1163, 7, 4625, 9, 15, 4, 485, 9, 256, 34, 723, 2, 137, 29, 16, 35, 4843, 1020, 132, 45, 43, 6, 147, 902, 15, 363, 210, 177, 84, 7, 1874, 4776, 8, 297, 2188, 832, 315, 14, 999, 48, 25, 26, 2648, 692, 33, 32, 45, 184, 578, 15, 2, 9, 355, 18, 4, 173]\n",
      "--- Label ---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Inspect a sample review and its label\n",
    "print(\"--- Review ---\")\n",
    "print(X_train[7])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label is an integer (0 for negative, 1 for positive), and the review itself is stored as a sequence of integers. These are word IDs that have been preassigned to individual words. To map them back to the original words, you can use the dictionary returned by `imdb.get_word_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 0us/step\n",
      "--- Review (with words) ---\n",
      "['the', 'this', 'of', 'plot', 'many', 'was', 'one', 'life', 'styles', 'and', 'was', 'one', 'saw', 'in', 'is', 'intent', 'showed', 'scene', 'it', 'by', 'success', 'unrealistic', 'was', 'how', 'least', 'called', 'and', 'those', 'this', 'of', 'and', 'fast', 'original', 'oh', 'and', 'and', 'or', 'them', 'are', 'was', 'kelly', 'be', 'possible', 'factory', 'to', 'supposed', 'all', 'with', 'and', 'but', 'him', 'god', 'for', 'obvious', 'this', 'and', 'no', 'remains', 'and', 'eyes', 'made', 'try', 'and', 'this', 'is', 'you', 'oh', 'and', 'we', 'of', 'yes', 'br', 'and', 'and', 'lady', 'br', 'screen', 'be', 'runs', 'protagonist', 'in', 'sheriff', 'with', 'be', 'behavior', 'almost', 'this', 'decides', 'spoiler', 'and', 'was', 'one', 'point', 'between', 'all', 'with', 'world', 'turns', 'in', 'beyond', 'think', 'being', 'is', 'soundtrack', 'alive', 'for', 'it', 'friends', 'was', 'least', 'made', 'this', 'as', 'unwatchable', 'of', 'on', 'it', 'oh', 'and', 'is', 'battles', 'in', 'of', 'reflect', 'and', 'and', 'br', 'of', 'sloppy', 'convincing', 'who', 'nicholas', 'and', 'most', 'of', 'explosion', 'takes', 'that', 'with', 'has', 'is', 'each', 'sentimental', 'naturally', 'ten', 'was', 'with', 'garbage', 'comment', 'take', 'was', 'superman', 'and', \"i'm\", 'of', 'problem', 'you', 'to', 'although', 'that', 'in', 'at', 'is', 'theme', 'and', 'done', 'anyway', \"'the\", 'dollars', '11', 'awe', 'really', 'what', 'that', 'me', 'is', 'stand', \"it's\", 'little', \"isn't\", 'one', 'will', 'half', 'are', 'good', 'seemed', 'those', 'talent', 'expect', 'and', 'to', 'film', 'good', 'br', '3rd', 'where', 'television', 'mean', 'should', 'movie', 'haunted', 'and', 'and', 'insult', 'classics', 'and', 'mysterious', 'and', 'animation', 'and', 'to', 'and', 'and', 'as', 'on', 'me', \"that's\", 'important', 'in', 'failure', 'and', 'strange', 'take', 'that', 'and', 'are', 'of', 'and', 'to', 'cinema', 'even', 'know', 'movie', 'is', 'effect', 'by', 'br', 'only', 'starts', 'and', \"can't\", 'seconds', 'this', 'is', 'zombie', 'way', 'treatment', 'really', 'best', \"can't\", 'better', 'of', 'provides']\n",
      "--- Label ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Map word IDs back to words\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print(\"--- Review (with words) ---\")\n",
    "print([id2word.get(i, \" \") for i in X_train[7]])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Pad sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Design an RNN model for sentiment analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "embedding_size=32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Train and evaluate model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 544s 22ms/step - loss: 0.5086 - acc: 0.7693 - val_loss: 0.4407 - val_acc: 0.8281\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 542s 22ms/step - loss: 0.3284 - acc: 0.8710 - val_loss: 0.7533 - val_acc: 0.7031\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 542s 22ms/step - loss: 0.2744 - acc: 0.8934 - val_loss: 0.3613 - val_acc: 0.8281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f58bbf048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 =  X_train[batch_size:], y_train[batch_size:]\n",
    "\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "model_file = \"rnn_model.h5\"  # HDF5 file\n",
    "model.save(os.path.join(os.getcwd(), model_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.88096\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)  # returns loss and other metrics specified in model.compile()\n",
    "print(\"Test accuracy:\", scores[1])  # scores[1] should correspond to accuracy if you passed in metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
